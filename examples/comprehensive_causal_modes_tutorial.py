#!/usr/bin/env python3
"""
ğŸ  å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹ï¼šåŠ å·æˆ¿ä»·é¢„æµ‹
=========================================

è¿™ä¸ªæ•™ç¨‹æ¼”ç¤ºæ‰€æœ‰5ç§CausalEngineæ¨ç†æ¨¡å¼åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚

æ•°æ®é›†ï¼šåŠ å·æˆ¿ä»·æ•°æ®é›†ï¼ˆCalifornia Housing Datasetï¼‰
- 20,640ä¸ªæ ·æœ¬
- 8ä¸ªç‰¹å¾ï¼ˆæˆ¿å±‹å¹´é¾„ã€æ”¶å…¥ã€äººå£ç­‰ï¼‰
- ç›®æ ‡ï¼šé¢„æµ‹æˆ¿ä»·ä¸­ä½æ•°

æˆ‘ä»¬å°†æ¯”è¾ƒæ‰€æœ‰æ–¹æ³•ï¼š
**æ ‡å‡†ç‰ˆæ¯”è¾ƒå›¾ï¼ˆ9ç§æ ¸å¿ƒæ–¹æ³•ï¼‰ï¼š**
1. sklearn MLPRegressorï¼ˆä¼ ç»Ÿç¥ç»ç½‘ç»œï¼‰
2. PyTorch MLPï¼ˆä¼ ç»Ÿæ·±åº¦å­¦ä¹ ï¼‰
3. Random Forestï¼ˆéšæœºæ£®æ—ï¼‰
4. XGBoostï¼ˆæ¢¯åº¦æå‡ï¼‰
5. LightGBMï¼ˆè½»é‡æ¢¯åº¦æå‡ï¼‰
6. CatBoostï¼ˆå¼ºåŠ›æ¢¯åº¦æå‡ï¼‰
7. CausalEngine - exogenousï¼ˆå¤–ç”Ÿå™ªå£°ä¸»å¯¼ï¼‰
8. CausalEngine - endogenousï¼ˆå†…ç”Ÿä¸ç¡®å®šæ€§ä¸»å¯¼ï¼‰
9. CausalEngine - standardï¼ˆå†…ç”Ÿ+å¤–ç”Ÿæ··åˆï¼‰

**æ‰©å±•ç‰ˆæ¯”è¾ƒå›¾ï¼ˆåŒ…å«æ‰€æœ‰13ç§æ–¹æ³•ï¼‰ï¼š**
- ä¸Šè¿°9ç§æ ¸å¿ƒæ–¹æ³• + 4ç§é¢å¤–æ–¹æ³•ï¼š
10. CausalEngine - deterministicï¼ˆç¡®å®šæ€§æ¨ç†ï¼‰
11. MLP Huberï¼ˆHuberæŸå¤±ç¨³å¥å›å½’ï¼‰
12. MLP Pinball Medianï¼ˆä¸­ä½æ•°å›å½’ï¼‰
13. MLP Cauchyï¼ˆCauchyæŸå¤±ç¨³å¥å›å½’ï¼‰

å…³é”®äº®ç‚¹ï¼š
- 4ç§CausalEngineæ¨ç†æ¨¡å¼çš„å…¨é¢å¯¹æ¯”
- 9ç§å¼ºåŠ›ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆåŒ…å«2ç§ç¥ç»ç½‘ç»œ+3ç§æ¢¯åº¦æå‡+1ç§éšæœºæ£®æ—+3ç§ç¨³å¥å›å½’ï¼‰
- çœŸå®ä¸–ç•Œæ•°æ®çš„é²æ£’æ€§æµ‹è¯•
- å› æœæ¨ç†vsä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½å·®å¼‚åˆ†æ
- æ ‡å‡†ç‰ˆ(9ç§æ ¸å¿ƒ)ä¸æ‰©å±•ç‰ˆ(13ç§å…¨éƒ¨)åŒé‡å¯è§†åŒ–

å®éªŒè®¾è®¡è¯´æ˜
==================================================================
æœ¬è„šæœ¬ä¸“æ³¨äºå…¨é¢è¯„ä¼°CausalEngineçš„4ç§æ¨ç†æ¨¡å¼ï¼Œæ—¨åœ¨æ­ç¤ºä¸åŒå› æœæ¨ç†ç­–ç•¥
åœ¨çœŸå®å›å½’ä»»åŠ¡ä¸Šçš„æ€§èƒ½ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚

æ ¸å¿ƒå®éªŒï¼šå…¨æ¨¡å¼æ€§èƒ½å¯¹æ¯” (åœ¨40%æ ‡ç­¾å™ªå£°ä¸‹)
--------------------------------------------------
- **ç›®æ ‡**: æ¯”è¾ƒæ‰€æœ‰4ç§CausalEngineæ¨¡å¼å’Œ9ç§ä¼ ç»Ÿæ–¹æ³•çš„é¢„æµ‹æ€§èƒ½ï¼ˆæ ‡å‡†ç‰ˆ9ç§æ ¸å¿ƒæ–¹æ³•ï¼Œæ‰©å±•ç‰ˆ13ç§æ€»æ–¹æ³•ï¼‰
- **è®¾ç½®**: 40%æ ‡ç­¾å™ªå£°ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œæ•°æ®è´¨é‡æŒ‘æˆ˜
- **å¯¹æ¯”æ¨¡å‹**: 
  - ä¼ ç»Ÿæ–¹æ³•ï¼ˆæ ¸å¿ƒ6ç§ï¼‰: sklearn MLP, PyTorch MLP, Random Forest, XGBoost, LightGBM, CatBoost
  - ç¨³å¥å›å½’ï¼ˆé¢å¤–3ç§ï¼‰: Huber MLP, Pinball MLP, Cauchy MLP
  - CausalEngineï¼ˆ4ç§æ¨¡å¼ï¼‰: deterministic, exogenous, endogenous, standard
- **åˆ†æé‡ç‚¹**: 
  - å“ªç§å› æœæ¨ç†æ¨¡å¼è¡¨ç°æœ€ä¼˜ï¼Ÿ
  - ä¸åŒæ¨¡å¼çš„æ€§èƒ½ç‰¹ç‚¹å’Œå·®å¼‚
  - å› æœæ¨ç†ç›¸å¯¹ä¼ ç»Ÿæ–¹æ³•çš„ä¼˜åŠ¿
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
import warnings
import os
import sys

# è®¾ç½®matplotlibåç«¯ä¸ºéäº¤äº’å¼ï¼Œé¿å…å¼¹å‡ºçª—å£
plt.switch_backend('Agg')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ¨¡å—
from causal_sklearn.benchmarks import BaselineBenchmark

warnings.filterwarnings('ignore')


class ComprehensiveTutorialConfig:
    """
    å…¨é¢æ•™ç¨‹é…ç½®ç±» - æµ‹è¯•æ‰€æœ‰CausalEngineæ¨¡å¼
    
    ğŸ”§ åœ¨è¿™é‡Œä¿®æ”¹å‚æ•°æ¥è‡ªå®šä¹‰å®éªŒè®¾ç½®ï¼
    """
    
    # ğŸ¯ æ•°æ®åˆ†å‰²å‚æ•°
    TEST_SIZE = 0.2          # æµ‹è¯•é›†æ¯”ä¾‹
    VAL_SIZE = 0.2           # éªŒè¯é›†æ¯”ä¾‹ (ç›¸å¯¹äºè®­ç»ƒé›†)
    RANDOM_STATE = 42        # éšæœºç§å­
    
    # ğŸ§  ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½® - æ‰€æœ‰ç¥ç»ç½‘ç»œæ–¹æ³•ä½¿ç”¨ç›¸åŒå‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒ
    # =========================================================================
    # ğŸ”§ åœ¨è¿™é‡Œä¿®æ”¹æ‰€æœ‰ç¥ç»ç½‘ç»œæ–¹æ³•çš„å…±åŒå‚æ•°ï¼
    NN_HIDDEN_SIZES = (128, 64, 32)                  # ç¥ç»ç½‘ç»œéšè—å±‚ç»“æ„
    NN_MAX_EPOCHS = 3000                         # æœ€å¤§è®­ç»ƒè½®æ•°
    NN_LEARNING_RATE = 0.01                      # å­¦ä¹ ç‡
    NN_PATIENCE = 200                            # æ—©åœpatience
    NN_TOLERANCE = 1e-4                          # æ—©åœtolerance
    # =========================================================================
    
    # ğŸ¤– CausalEngineå‚æ•° - æµ‹è¯•4ç§æœ‰æ•ˆæ¨¡å¼ï¼ˆç§»é™¤samplingï¼‰
    CAUSAL_MODES = ['deterministic', 'exogenous', 'endogenous', 'standard']
    CAUSAL_HIDDEN_SIZES = NN_HIDDEN_SIZES        # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_MAX_EPOCHS = NN_MAX_EPOCHS            # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_LR = NN_LEARNING_RATE                 # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_PATIENCE = NN_PATIENCE                # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_TOL = NN_TOLERANCE                    # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_GAMMA_INIT = 1.0                      # gammaåˆå§‹åŒ–
    CAUSAL_B_NOISE_INIT = 1.0                    # b_noiseåˆå§‹åŒ–
    CAUSAL_B_NOISE_TRAINABLE = True              # b_noiseæ˜¯å¦å¯è®­ç»ƒ
    
    # ğŸ§  ä¼ ç»Ÿç¥ç»ç½‘ç»œæ–¹æ³•å‚æ•° - ä½¿ç”¨ç»Ÿä¸€é…ç½®
    SKLEARN_HIDDEN_LAYERS = NN_HIDDEN_SIZES      # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    SKLEARN_MAX_ITER = NN_MAX_EPOCHS             # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    SKLEARN_LR = NN_LEARNING_RATE                # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    
    PYTORCH_EPOCHS = NN_MAX_EPOCHS               # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    PYTORCH_LR = NN_LEARNING_RATE                # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    PYTORCH_PATIENCE = NN_PATIENCE               # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    
    # ğŸ“Š å®éªŒå‚æ•°
    ANOMALY_RATIO = 0.4                         # æ ‡ç­¾å¼‚å¸¸æ¯”ä¾‹ (æ ¸å¿ƒå®éªŒé»˜è®¤å€¼: 40%å™ªå£°æŒ‘æˆ˜)
    SAVE_PLOTS = True                            # æ˜¯å¦ä¿å­˜å›¾è¡¨
    VERBOSE = True                               # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
    
    # ğŸ¯ åŸºå‡†æ–¹æ³•é…ç½® - åŒ…å«9ç§ä¼ ç»Ÿæ–¹æ³•ï¼ˆä¸sklearn-styleç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    BASELINE_METHODS = [
        'sklearn_mlp',          # sklearn MLPRegressor
        'pytorch_mlp',          # PyTorch MLP
        'random_forest',        # éšæœºæ£®æ—
        'xgboost',              # XGBoost
        'lightgbm',             # LightGBM  
        'catboost',             # CatBoost - å¼ºåŠ›æ¢¯åº¦æå‡
        'mlp_huber',            # MLP Huberï¼ˆHuberæŸå¤±ç¨³å¥å›å½’ï¼‰
        'mlp_pinball_median',   # MLP Pinball Medianï¼ˆä¸­ä½æ•°å›å½’ï¼‰
        'mlp_cauchy'            # MLP Cauchyï¼ˆCauchyæŸå¤±ç¨³å¥å›å½’ï¼‰
    ]
    
    # æˆ–è€…ä½¿ç”¨é¢„å®šä¹‰ç»„åˆï¼š
    # BASELINE_METHODS = 'group:comprehensive'  # ä½¿ç”¨é¢„å®šä¹‰çš„comprehensiveç»„åˆ
    # BASELINE_METHODS = 'group:competitive'    # ä½¿ç”¨é¢„å®šä¹‰çš„competitiveç»„åˆ
    
    # ğŸ“ˆ å¯è§†åŒ–å‚æ•°
    FIGURE_DPI = 300                             # å›¾è¡¨åˆ†è¾¨ç‡
    FIGURE_SIZE_ANALYSIS = (16, 12)              # æ•°æ®åˆ†æå›¾è¡¨å¤§å°
    FIGURE_SIZE_PERFORMANCE = (24, 20)           # æ€§èƒ½å¯¹æ¯”å›¾è¡¨å¤§å°ï¼ˆæ›´å¤§ä»¥å®¹çº³13ä¸ªæ–¹æ³•ï¼‰
    FIGURE_SIZE_MODES_COMPARISON = (18, 12)      # CausalEngineæ¨¡å¼å¯¹æ¯”å›¾è¡¨å¤§å°
    
    # ğŸ“ è¾“å‡ºç›®å½•å‚æ•°
    OUTPUT_DIR = "results/comprehensive_causal_modes"


class ComprehensiveCausalModesTutorial:
    """
    å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹ç±»
    
    æ¼”ç¤ºæ‰€æœ‰5ç§CausalEngineæ¨ç†æ¨¡å¼åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„æ€§èƒ½ç‰¹ç‚¹
    """
    
    def __init__(self, config=None):
        self.config = config if config is not None else ComprehensiveTutorialConfig()
        self.X = None
        self.y = None
        self.feature_names = None
        self.results = {}
        self._ensure_output_dir()
    
    def _ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.config.OUTPUT_DIR):
            os.makedirs(self.config.OUTPUT_DIR)
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {self.config.OUTPUT_DIR}/")
    
    def _get_output_path(self, filename):
        """è·å–è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        return os.path.join(self.config.OUTPUT_DIR, filename)
        
    def load_and_explore_data(self, verbose=True):
        """åŠ è½½å¹¶æ¢ç´¢åŠ å·æˆ¿ä»·æ•°æ®é›†"""
        if verbose:
            print("ğŸ  å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹ - åŠ å·æˆ¿ä»·é¢„æµ‹")
            print("=" * 70)
            print("ğŸ“Š æ­£åœ¨åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®
        housing = fetch_california_housing()
        self.X, self.y = housing.data, housing.target
        self.feature_names = housing.feature_names
        
        if verbose:
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
            print(f"   - æ ·æœ¬æ•°é‡: {self.X.shape[0]:,}")
            print(f"   - ç‰¹å¾æ•°é‡: {self.X.shape[1]}")
            print(f"   - ç‰¹å¾åç§°: {', '.join(self.feature_names)}")
            print(f"   - ç›®æ ‡èŒƒå›´: ${self.y.min():.2f} - ${self.y.max():.2f} (ç™¾ä¸‡ç¾å…ƒ)")
            print(f"   - ç›®æ ‡å‡å€¼: ${self.y.mean():.2f}")
            print(f"   - ç›®æ ‡æ ‡å‡†å·®: ${self.y.std():.2f}")
        
        return self.X, self.y
    
    def visualize_data(self, save_plots=None):
        """æ•°æ®å¯è§†åŒ–åˆ†æ"""
        if save_plots is None:
            save_plots = self.config.SAVE_PLOTS
            
        print("\nğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ")
        print("-" * 30)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_ANALYSIS)
        fig.suptitle('California Housing Dataset Analysis - Comprehensive CausalEngine Modes Tutorial', fontsize=16, fontweight='bold')
        
        # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ
        axes[0, 0].hist(self.y, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('House Price Distribution')
        axes[0, 0].set_xlabel('House Price ($100k)')
        axes[0, 0].set_ylabel('Frequency')
        axes[0, 0].axvline(self.y.mean(), color='red', linestyle='--', label=f'Mean: ${self.y.mean():.2f}')
        axes[0, 0].legend()
        
        # 2. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
        df = pd.DataFrame(self.X, columns=self.feature_names)
        df['MedHouseVal'] = self.y
        corr_matrix = df.corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, ax=axes[0, 1], cbar_kws={'shrink': 0.8})
        axes[0, 1].set_title('Feature Correlation Matrix')
        
        # 3. ç‰¹å¾åˆ†å¸ƒç®±çº¿å›¾
        df_features = pd.DataFrame(self.X, columns=self.feature_names)
        df_features_normalized = (df_features - df_features.mean()) / df_features.std()
        df_features_normalized.boxplot(ax=axes[1, 0])
        axes[1, 0].set_title('Feature Distribution (Standardized)')
        axes[1, 0].set_xlabel('Features')
        axes[1, 0].set_ylabel('Standardized Values')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. æœ€é‡è¦ç‰¹å¾ä¸ç›®æ ‡çš„æ•£ç‚¹å›¾
        most_corr_feature = corr_matrix['MedHouseVal'].abs().sort_values(ascending=False).index[1]
        most_corr_idx = list(self.feature_names).index(most_corr_feature)
        axes[1, 1].scatter(self.X[:, most_corr_idx], self.y, alpha=0.5, s=1)
        axes[1, 1].set_title(f'Most Correlated Feature: {most_corr_feature}')
        axes[1, 1].set_xlabel(most_corr_feature)
        axes[1, 1].set_ylabel('House Price ($100k)')
        
        plt.tight_layout()
        
        if save_plots:
            output_path = self._get_output_path('comprehensive_data_analysis.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š æ•°æ®åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…å†…å­˜æ³„æ¼
        
        # æ•°æ®ç»Ÿè®¡æ‘˜è¦
        print("\nğŸ“‹ æ•°æ®ç»Ÿè®¡æ‘˜è¦:")
        print(f"  - æœ€ç›¸å…³ç‰¹å¾: {most_corr_feature} (ç›¸å…³ç³»æ•°: {corr_matrix.loc[most_corr_feature, 'MedHouseVal']:.3f})")
        print(f"  - å¼‚å¸¸å€¼æ£€æµ‹: {np.sum(np.abs(self.y - self.y.mean()) > 3 * self.y.std())} ä¸ªæ½œåœ¨å¼‚å¸¸å€¼")
        print(f"  - æ•°æ®å®Œæ•´æ€§: æ— ç¼ºå¤±å€¼" if not np.any(np.isnan(self.X)) else "  - è­¦å‘Š: å­˜åœ¨ç¼ºå¤±å€¼")
    
    def run_comprehensive_benchmark(self, test_size=None, val_size=None, anomaly_ratio=None, verbose=None):
        """è¿è¡Œå…¨é¢çš„åŸºå‡†æµ‹è¯• - åŒ…å«æ‰€æœ‰5ç§CausalEngineæ¨¡å¼"""
        # ä½¿ç”¨é…ç½®å‚æ•°ä½œä¸ºé»˜è®¤å€¼
        if test_size is None:
            test_size = self.config.TEST_SIZE
        if val_size is None:
            val_size = self.config.VAL_SIZE
        if anomaly_ratio is None:
            anomaly_ratio = self.config.ANOMALY_RATIO
        if verbose is None:
            verbose = self.config.VERBOSE
            
        if verbose:
            print("\nğŸš€ å¼€å§‹å…¨é¢åŸºå‡†æµ‹è¯• - æµ‹è¯•æ‰€æœ‰5ç§CausalEngineæ¨¡å¼")
            print("=" * 80)
            print(f"ğŸ”§ å®éªŒé…ç½®:")
            print(f"   - æµ‹è¯•é›†æ¯”ä¾‹: {test_size:.1%}")
            print(f"   - éªŒè¯é›†æ¯”ä¾‹: {val_size:.1%}")
            print(f"   - å¼‚å¸¸æ ‡ç­¾æ¯”ä¾‹: {anomaly_ratio:.1%}")
            print(f"   - éšæœºç§å­: {self.config.RANDOM_STATE}")
            print(f"   - CausalEngineæ¨¡å¼: {', '.join(self.config.CAUSAL_MODES)}")
            print(f"   - CausalEngineç½‘ç»œ: {self.config.CAUSAL_HIDDEN_SIZES}")
            print(f"   - æœ€å¤§è®­ç»ƒè½®æ•°: {self.config.CAUSAL_MAX_EPOCHS}")
            print(f"   - æ—©åœpatience: {self.config.CAUSAL_PATIENCE}")
            baseline_count = len(self.config.BASELINE_METHODS)
            total_methods = len(self.config.CAUSAL_MODES) + baseline_count
            print(f"   - åŸºå‡†æ–¹æ³•: {self.config.BASELINE_METHODS}")
            print(f"   - æ€»è®¡å¯¹æ¯”æ–¹æ³•: {total_methods} ç§ ({len(self.config.CAUSAL_MODES)}ç§CausalEngine + {baseline_count}ç§ä¼ ç»Ÿ)")
        
        # ä½¿ç”¨åŸºå‡†æµ‹è¯•æ¨¡å—
        benchmark = BaselineBenchmark()
        
        # æ‰“å°å¯ç”¨æ–¹æ³•æŠ¥å‘Š
        if verbose:
            benchmark.print_method_availability()
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        self.results = benchmark.compare_models(
            X=self.X,
            y=self.y,
            task_type='regression',
            baseline_methods=self.config.BASELINE_METHODS,  # æ–°å¢ï¼šä½¿ç”¨é…ç½®çš„åŸºå‡†æ–¹æ³•
            test_size=test_size,
            val_size=val_size,
            anomaly_ratio=anomaly_ratio,
            random_state=self.config.RANDOM_STATE,
            verbose=verbose,
            # CausalEngineå‚æ•° - åŒ…å«æ‰€æœ‰5ç§æ¨¡å¼
            causal_modes=self.config.CAUSAL_MODES,
            hidden_sizes=self.config.CAUSAL_HIDDEN_SIZES,
            max_epochs=self.config.CAUSAL_MAX_EPOCHS,
            lr=self.config.CAUSAL_LR,
            patience=self.config.CAUSAL_PATIENCE,
            tol=self.config.CAUSAL_TOL,
            gamma_init=self.config.CAUSAL_GAMMA_INIT,
            b_noise_init=self.config.CAUSAL_B_NOISE_INIT,
            b_noise_trainable=self.config.CAUSAL_B_NOISE_TRAINABLE,
            # sklearn/PyTorchå‚æ•°
            hidden_layer_sizes=self.config.SKLEARN_HIDDEN_LAYERS,
            max_iter=self.config.SKLEARN_MAX_ITER,
            learning_rate=self.config.SKLEARN_LR
        )
        
        if verbose:
            print(f"\nğŸ“Š å…¨é¢åŸºå‡†æµ‹è¯•ç»“æœ (å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.0%})")
            benchmark.print_results(self.results, 'regression')
        
        return self.results
    
    def analyze_causal_modes_performance(self, verbose=True):
        """ä¸“é—¨åˆ†æCausalEngineä¸åŒæ¨¡å¼çš„æ€§èƒ½ç‰¹ç‚¹"""
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        if verbose:
            print("\nğŸ”¬ CausalEngineæ¨¡å¼æ·±åº¦åˆ†æ")
            print("=" * 70)
        
        # æå–CausalEngineæ¨¡å¼ç»“æœ
        causal_results = {}
        traditional_results = {}
        
        for method, metrics in self.results.items():
            if method in self.config.CAUSAL_MODES:
                causal_results[method] = metrics
            else:
                # æ‰€æœ‰éCausalEngineçš„æ–¹æ³•éƒ½ç®—ä½œä¼ ç»Ÿæ–¹æ³•
                traditional_results[method] = metrics
        
        if verbose:
            print(f"ğŸ¯ CausalEngineæ¨¡å¼æ€§èƒ½å¯¹æ¯” (å…±{len(causal_results)}ç§æ¨¡å¼):")
            print("-" * 50)
            
            # æŒ‰MdAEåˆ†æ•°æ’åºï¼ˆè¶Šå°è¶Šå¥½ï¼‰
            causal_mdae_scores = {mode: metrics['test']['MdAE'] for mode, metrics in causal_results.items()}
            sorted_causal = sorted(causal_mdae_scores.items(), key=lambda x: x[1])  # å‡åºæ’åˆ—
            
            for i, (mode, mdae) in enumerate(sorted_causal, 1):
                mae = causal_results[mode]['test']['MAE']
                r2 = causal_results[mode]['test']['RÂ²']
                print(f"   {i}. {mode:<12} - MdAE: {mdae:.3f}, MAE: {mae:.3f}, RÂ²: {r2:.4f}")
            
            # æ¨¡å¼ç‰¹ç‚¹åˆ†æ
            print(f"\nğŸ“Š æ¨¡å¼ç‰¹ç‚¹åˆ†æ:")
            print("-" * 30)
            
            best_mode = sorted_causal[0][0]
            worst_mode = sorted_causal[-1][0]
            performance_gap = sorted_causal[-1][1] - sorted_causal[0][1]  # æœ€å·® - æœ€å¥½ (å› ä¸ºMdAEè¶Šå°è¶Šå¥½)
            
            print(f"   ğŸ† æœ€ä½³æ¨¡å¼: {best_mode} (MdAE = {sorted_causal[0][1]:.3f})")
            print(f"   ğŸ“‰ æœ€å¼±æ¨¡å¼: {worst_mode} (MdAE = {sorted_causal[-1][1]:.3f})")
            print(f"   ğŸ“ æ€§èƒ½å·®è·: {performance_gap:.3f} ({performance_gap/sorted_causal[0][1]*100:.1f}%)")
            
            # ä¸ä¼ ç»Ÿæ–¹æ³•æ¯”è¾ƒï¼ˆåŸºäºMdAEï¼‰
            if traditional_results:
                print(f"\nğŸ†š CausalEngine vs ä¼ ç»Ÿæ–¹æ³•:")
                print("-" * 40)
                
                traditional_mdae_scores = {method: metrics['test']['MdAE'] for method, metrics in traditional_results.items()}
                best_traditional = min(traditional_mdae_scores.keys(), key=lambda x: traditional_mdae_scores[x])  # æœ€å°MdAEæœ€å¥½
                best_traditional_mdae = traditional_mdae_scores[best_traditional]
                
                print(f"   æœ€ä½³ä¼ ç»Ÿæ–¹æ³•: {best_traditional} (MdAE = {best_traditional_mdae:.3f})")
                print(f"   æœ€ä½³CausalEngine: {best_mode} (MdAE = {sorted_causal[0][1]:.3f})")
                
                improvement = (best_traditional_mdae - sorted_causal[0][1]) / best_traditional_mdae * 100  # æ­£å€¼è¡¨ç¤ºCausalEngineæ›´å¥½
                print(f"   æ€§èƒ½æå‡: {improvement:+.2f}%")
                
                # ç»Ÿè®¡æœ‰å¤šå°‘CausalEngineæ¨¡å¼ä¼˜äºæœ€ä½³ä¼ ç»Ÿæ–¹æ³•
                better_modes = sum(1 for _, mdae in sorted_causal if mdae < best_traditional_mdae)
                print(f"   ä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„CausalEngineæ¨¡å¼: {better_modes}/{len(sorted_causal)}")
        
        return causal_results, traditional_results
    
    def create_comprehensive_performance_visualization(self, save_plot=None, extended=False):
        """åˆ›å»ºå…¨é¢çš„æ€§èƒ½å¯è§†åŒ–å›¾è¡¨ - æ”¯æŒæ ‡å‡†ç‰ˆå’Œæ‰©å±•ç‰ˆ"""
        if save_plot is None:
            save_plot = self.config.SAVE_PLOTS
            
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        chart_type = "æ‰©å±•ç‰ˆ" if extended else "æ ‡å‡†ç‰ˆ"
        print(f"\nğŸ“Š åˆ›å»ºå…¨é¢æ€§èƒ½å¯è§†åŒ–å›¾è¡¨ ({chart_type})")
        print("-" * 40)
        
        # å‡†å¤‡æ•°æ® - æ ¹æ®æ‰©å±•æ ‡å¿—å†³å®šåŒ…å«çš„æ–¹æ³•
        if extended:
            # æ‰©å±•ç‰ˆï¼šåŒ…å«æ‰€æœ‰å¯ç”¨æ–¹æ³•
            all_available_methods = list(self.results.keys())
            # æŒ‰ç±»å‹æ’åºï¼šå…ˆä¼ ç»Ÿæ–¹æ³•ï¼ŒåCausalEngine
            traditional_methods = [m for m in all_available_methods if m not in self.config.CAUSAL_MODES]
            causal_methods = [m for m in self.config.CAUSAL_MODES if m in self.results]
            methods = traditional_methods + causal_methods
        else:
            # æ ‡å‡†ç‰ˆï¼šåŒ…å«9ç§æ ¸å¿ƒæ–¹æ³•ï¼ˆé™¤äº†robust MLPæ–¹æ³•ï¼‰
            robust_mlp_methods = ['mlp_huber', 'mlp_pinball_median', 'mlp_cauchy']  # æ’é™¤çš„robust MLPæ–¹æ³•
            standard_traditional = [m for m in self.results.keys() 
                                  if m not in self.config.CAUSAL_MODES and m not in robust_mlp_methods]
            causal_methods = [m for m in self.config.CAUSAL_MODES if m in self.results]
            methods = standard_traditional + causal_methods
        
        # ä¸ºä¸åŒç±»å‹çš„æ–¹æ³•è®¾ç½®é¢œè‰²
        colors = []
        for method in methods:
            if method in self.config.CAUSAL_MODES:
                colors.append('#2ca02c')  # ç»¿è‰²ç³» - CausalEngine
            else:
                colors.append('#1f77b4')  # è“è‰²ç³» - ä¼ ç»Ÿæ–¹æ³•
        
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        
        # åˆ›å»ºå­å›¾ - 2x2å¸ƒå±€å±•ç¤º4ä¸ªæŒ‡æ ‡
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_PERFORMANCE)
        title_suffix = " (Extended with All Methods)" if extended else ""
        fig.suptitle(f'Comprehensive CausalEngine Modes vs Traditional Methods{title_suffix}\nCalifornia Housing Performance (40% Label Noise)', 
                     fontsize=16, fontweight='bold')
        axes = axes.flatten()
        
        for i, metric in enumerate(metrics):
            values = [self.results[method]['test'][metric] for method in methods]
            
            bars = axes[i].bar(range(len(methods)), values, color=colors, alpha=0.8, edgecolor='black')
            axes[i].set_title(f'{metric} (Test Set)', fontweight='bold')
            axes[i].set_ylabel(metric)
            
            # è®¾ç½®Xè½´æ ‡ç­¾ - æ™ºèƒ½å¤„ç†å„ç§æ–¹æ³•å
            method_labels = []
            for method in methods:
                if method in self.config.CAUSAL_MODES:
                    method_labels.append(f'CausalEngine\n({method})')
                elif 'sklearn' in method.lower() or method == 'sklearn':
                    method_labels.append('sklearn\nMLP')
                elif 'pytorch' in method.lower() or method == 'pytorch':
                    method_labels.append('PyTorch\nMLP')
                else:
                    # å…¶ä»–ä¼ ç»Ÿæ–¹æ³•ï¼Œç®€åŒ–æ˜¾ç¤ºåç§°
                    display_name = method.replace('_', ' ').title()
                    if len(display_name) > 12:
                        # é•¿åç§°åˆ†è¡Œæ˜¾ç¤º
                        words = display_name.split()
                        if len(words) > 1:
                            display_name = f"{words[0]}\n{' '.join(words[1:])}"
                    method_labels.append(display_name)
            
            axes[i].set_xticks(range(len(methods)))
            axes[i].set_xticklabels(method_labels, rotation=45, ha='right', fontsize=8)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, values):
                height = bar.get_height()
                axes[i].text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=8)
            
            # é«˜äº®æœ€ä½³ç»“æœ
            if metric == 'RÂ²':
                best_idx = values.index(max(values))
            else:
                best_idx = values.index(min(values))
            bars[best_idx].set_color('gold')
            bars[best_idx].set_edgecolor('red')
            bars[best_idx].set_linewidth(3)
        
        plt.tight_layout()
        
        if save_plot:
            filename = 'comprehensive_performance_comparison_extended.png' if extended else 'comprehensive_performance_comparison.png'
            output_path = self._get_output_path(filename)
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š {chart_type}å…¨é¢æ€§èƒ½å›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()
    
    def create_causal_modes_comparison(self, save_plot=None):
        """åˆ›å»ºä¸“é—¨çš„CausalEngineæ¨¡å¼å¯¹æ¯”å›¾è¡¨"""
        if save_plot is None:
            save_plot = self.config.SAVE_PLOTS
            
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("\nğŸ“Š åˆ›å»ºCausalEngineæ¨¡å¼ä¸“é¡¹å¯¹æ¯”å›¾è¡¨")
        print("-" * 45)
        
        # æå–CausalEngineæ¨¡å¼ç»“æœ
        causal_methods = [m for m in self.config.CAUSAL_MODES if m in self.results]
        
        if len(causal_methods) < 2:
            print("âŒ éœ€è¦è‡³å°‘2ç§CausalEngineæ¨¡å¼æ¥è¿›è¡Œå¯¹æ¯”")
            return
        
        # åˆ›å»ºé›·è¾¾å›¾æ˜¾ç¤ºCausalEngineæ¨¡å¼çš„å¤šç»´æ€§èƒ½
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.config.FIGURE_SIZE_MODES_COMPARISON)
        fig.suptitle('CausalEngine Modes Detailed Comparison', fontsize=16, fontweight='bold')
        
        # å·¦å›¾ï¼šæ€§èƒ½æ¡å½¢å›¾
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        colors = plt.cm.Set3(np.linspace(0, 1, len(causal_methods)))
        
        x = np.arange(len(metrics))
        width = 0.15
        
        for i, method in enumerate(causal_methods):
            values = [self.results[method]['test'][metric] for metric in metrics]
            ax1.bar(x + i * width, values, width, label=f'{method}', color=colors[i], alpha=0.8)
        
        ax1.set_xlabel('Metrics')
        ax1.set_ylabel('Values')
        ax1.set_title('CausalEngine Modes Performance Comparison')
        ax1.set_xticks(x + width * (len(causal_methods) - 1) / 2)
        ax1.set_xticklabels(metrics)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å³å›¾ï¼šMdAEæ€§èƒ½æ’åï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        mdae_scores = [(method, self.results[method]['test']['MdAE']) for method in causal_methods]
        mdae_scores.sort(key=lambda x: x[1])  # æŒ‰å‡åºæ’åˆ—ï¼Œå› ä¸ºMdAEè¶Šå°è¶Šå¥½
        
        methods_sorted = [item[0] for item in mdae_scores]
        mdae_values = [item[1] for item in mdae_scores]
        
        bars = ax2.bar(range(len(methods_sorted)), mdae_values, color=colors[:len(methods_sorted)], alpha=0.8)
        ax2.set_xlabel('CausalEngine Modes')
        ax2.set_ylabel('MdAE (Median Absolute Error)')
        ax2.set_title('CausalEngine Modes MdAE Performance Ranking')
        ax2.set_xticks(range(len(methods_sorted)))
        ax2.set_xticklabels(methods_sorted, rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, mdae_values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.02,
                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # é«˜äº®æœ€ä½³æ¨¡å¼ï¼ˆMdAEæœ€å°çš„ï¼‰
        bars[0].set_color('gold')
        bars[0].set_edgecolor('red')
        bars[0].set_linewidth(3)
        
        plt.tight_layout()
        
        if save_plot:
            output_path = self._get_output_path('causal_modes_detailed_comparison.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š CausalEngineæ¨¡å¼å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()
    
    def print_comprehensive_summary(self):
        """æ‰“å°å…¨é¢çš„æ€»ç»“æŠ¥å‘Š"""
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("\nğŸ“‹ å…¨é¢å®éªŒæ€»ç»“æŠ¥å‘Š")
        print("=" * 80)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_methods = len(self.results)
        causal_methods = len([m for m in self.results if m in self.config.CAUSAL_MODES])
        traditional_methods = len([m for m in self.results if m in ['sklearn', 'pytorch']])
        
        print(f"ğŸ”¢ å®éªŒè§„æ¨¡:")
        print(f"   - æ€»è®¡æµ‹è¯•æ–¹æ³•: {total_methods}")
        print(f"   - CausalEngineæ¨¡å¼: {causal_methods}")
        print(f"   - ä¼ ç»Ÿæ–¹æ³•: {traditional_methods}")
        print(f"   - æ•°æ®é›†å¤§å°: {self.X.shape[0]:,} æ ·æœ¬ Ã— {self.X.shape[1]} ç‰¹å¾")
        print(f"   - å¼‚å¸¸æ ‡ç­¾æ¯”ä¾‹: {self.config.ANOMALY_RATIO:.1%}")
        
        # æ€§èƒ½æ’åï¼ˆæŒ‰MdAEåˆ†æ•°ï¼Œè¶Šå°è¶Šå¥½ï¼‰
        print(f"\nğŸ† æ€»ä½“æ€§èƒ½æ’å (æŒ‰MdAEåˆ†æ•°):")
        print("-" * 50)
        
        all_mdae_scores = [(method, metrics['test']['MdAE']) for method, metrics in self.results.items()]
        all_mdae_scores.sort(key=lambda x: x[1])  # å‡åºæ’åˆ—ï¼ŒMdAEè¶Šå°è¶Šå¥½
        
        for i, (method, mdae) in enumerate(all_mdae_scores, 1):
            method_type = "CausalEngine" if method in self.config.CAUSAL_MODES else "Traditional"
            r2 = self.results[method]['test']['RÂ²']
            print(f"   {i:2d}. {method:<15} ({method_type:<12}) - MdAE: {mdae:.3f}, RÂ²: {r2:.4f}")
        
        # CausalEngineä¼˜åŠ¿åˆ†æï¼ˆåŸºäºMdAEï¼‰
        print(f"\nğŸ¯ CausalEngineæ¨¡å¼åˆ†æ:")
        print("-" * 40)
        
        causal_results = [(method, metrics['test']['MdAE']) for method, metrics in self.results.items() 
                         if method in self.config.CAUSAL_MODES]
        traditional_results = [(method, metrics['test']['MdAE']) for method, metrics in self.results.items() 
                              if method in ['sklearn', 'pytorch']]
        
        if causal_results and traditional_results:
            best_causal = min(causal_results, key=lambda x: x[1])  # æœ€å°MdAEæœ€å¥½
            best_traditional = min(traditional_results, key=lambda x: x[1])  # æœ€å°MdAEæœ€å¥½
            
            print(f"   æœ€ä½³CausalEngineæ¨¡å¼: {best_causal[0]} (MdAE = {best_causal[1]:.3f})")
            print(f"   æœ€ä½³ä¼ ç»Ÿæ–¹æ³•: {best_traditional[0]} (MdAE = {best_traditional[1]:.3f})")
            
            improvement = (best_traditional[1] - best_causal[1]) / best_traditional[1] * 100  # æ­£å€¼è¡¨ç¤ºCausalEngineæ›´å¥½
            print(f"   æ€§èƒ½æå‡: {improvement:+.2f}%")
            
            # ç»Ÿè®¡ä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„CausalEngineæ¨¡å¼æ•°é‡
            better_causal_count = sum(1 for _, mdae in causal_results if mdae < best_traditional[1])
            print(f"   ä¼˜äºæœ€ä½³ä¼ ç»Ÿæ–¹æ³•çš„CausalEngineæ¨¡å¼: {better_causal_count}/{len(causal_results)}")
        
        # å…³é”®å‘ç°ï¼ˆåŸºäºMdAEï¼‰
        print(f"\nğŸ’¡ å…³é”®å‘ç°:")
        print("-" * 20)
        
        if len(all_mdae_scores) > 0:
            top_method = all_mdae_scores[0]  # MdAEæœ€å°çš„æ–¹æ³•æœ€å¥½
            if top_method[0] in self.config.CAUSAL_MODES:
                print(f"   âœ… CausalEngineæ¨¡å¼ '{top_method[0]}' åœ¨MdAEæŒ‡æ ‡ä¸Šå–å¾—æœ€ä½³æ€§èƒ½")
                print(f"   âœ… å› æœæ¨ç†åœ¨ç¨³å¥æ€§æ–¹é¢æ˜¾ç¤ºå‡ºæ˜æ˜¾ä¼˜åŠ¿")
            else:
                print(f"   âš ï¸ ä¼ ç»Ÿæ–¹æ³• '{top_method[0]}' åœ¨MdAEæŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä¼˜")
                print(f"   âš ï¸ å»ºè®®è¿›ä¸€æ­¥è°ƒä¼˜CausalEngineå‚æ•°")
            
            # æ£€æŸ¥CausalEngineæ¨¡å¼é—´çš„å·®å¼‚ï¼ˆåŸºäºMdAEï¼‰
            if len(causal_results) > 1:
                causal_mdae_values = [mdae for _, mdae in causal_results]
                causal_std = np.std(causal_mdae_values)
                print(f"   ğŸ“Š CausalEngineæ¨¡å¼é—´MdAEæ ‡å‡†å·®: {causal_std:.4f}")
                if causal_std < 0.02:
                    print(f"   ğŸ“ˆ ä¸åŒCausalEngineæ¨¡å¼MdAEæ€§èƒ½è¾ƒä¸ºæ¥è¿‘")
                else:
                    print(f"   ğŸ“ˆ ä¸åŒCausalEngineæ¨¡å¼MdAEå­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®å¼‚")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹"""
    print("ğŸ  å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹")
    print("ğŸ¯ ç›®æ ‡ï¼šæµ‹è¯•æ‰€æœ‰5ç§CausalEngineæ¨ç†æ¨¡å¼åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„è¡¨ç°")
    print("=" * 90)
    
    # åˆ›å»ºé…ç½®å®ä¾‹
    config = ComprehensiveTutorialConfig()
    
    print(f"ğŸ”§ å½“å‰é…ç½®:")
    print(f"   - CausalEngineæ¨¡å¼: {', '.join(config.CAUSAL_MODES)} (å…±{len(config.CAUSAL_MODES)}ç§)")
    print(f"   - ç½‘ç»œæ¶æ„: {config.CAUSAL_HIDDEN_SIZES}")
    print(f"   - æœ€å¤§è½®æ•°: {config.CAUSAL_MAX_EPOCHS}")
    print(f"   - æ—©åœpatience: {config.CAUSAL_PATIENCE}")
    print(f"   - å¼‚å¸¸æ¯”ä¾‹: {config.ANOMALY_RATIO:.1%}")
    print(f"   - æ€»è®¡å¯¹æ¯”æ–¹æ³•: {len(config.CAUSAL_MODES) + len(config.BASELINE_METHODS)} ç§")
    print(f"   - è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}/")
    print()
    
    # åˆ›å»ºæ•™ç¨‹å®ä¾‹
    tutorial = ComprehensiveCausalModesTutorial(config)
    
    # 1. åŠ è½½å’Œæ¢ç´¢æ•°æ®
    tutorial.load_and_explore_data()
    
    # 2. æ•°æ®å¯è§†åŒ–
    tutorial.visualize_data()
    
    # 3. è¿è¡Œå…¨é¢åŸºå‡†æµ‹è¯• - æµ‹è¯•æ‰€æœ‰5ç§CausalEngineæ¨¡å¼
    tutorial.run_comprehensive_benchmark()
    
    # 4. ä¸“é—¨åˆ†æCausalEngineæ¨¡å¼æ€§èƒ½
    tutorial.analyze_causal_modes_performance()
    
    # 5. åˆ›å»ºå…¨é¢æ€§èƒ½å¯è§†åŒ– - ç”Ÿæˆæ ‡å‡†ç‰ˆå’Œæ‰©å±•ç‰ˆ
    tutorial.create_comprehensive_performance_visualization(extended=False)  # æ ‡å‡†ç‰ˆ
    tutorial.create_comprehensive_performance_visualization(extended=True)   # æ‰©å±•ç‰ˆ
    
    # 6. åˆ›å»ºCausalEngineæ¨¡å¼ä¸“é¡¹å¯¹æ¯”
    tutorial.create_causal_modes_comparison()
    
    # 7. æ‰“å°å…¨é¢æ€»ç»“æŠ¥å‘Š
    tutorial.print_comprehensive_summary()
    
    print("\nğŸ‰ å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹å®Œæˆï¼")
    print("ğŸ“‹ å®éªŒæ€»ç»“:")
    print(f"   - ä½¿ç”¨äº†çœŸå®ä¸–ç•Œçš„åŠ å·æˆ¿ä»·æ•°æ®é›† ({tutorial.X.shape[0]:,} æ ·æœ¬)")
    print(f"   - æµ‹è¯•äº†æ‰€æœ‰ {len(config.CAUSAL_MODES)} ç§CausalEngineæ¨ç†æ¨¡å¼")
    print(f"   - ä¸ {len(config.BASELINE_METHODS)} ç§ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œäº†å…¨é¢å¯¹æ¯”")
    print(f"   - åŸºå‡†æ–¹æ³•åŒ…æ‹¬: {', '.join(config.BASELINE_METHODS[:3])}ç­‰")
    print(f"   - åœ¨ {config.ANOMALY_RATIO:.0%} æ ‡ç­¾å™ªå£°ç¯å¢ƒä¸‹éªŒè¯äº†é²æ£’æ€§")
    print("   - æä¾›äº†è¯¦ç»†çš„æ¨¡å¼ç‰¹ç‚¹åˆ†æå’Œå¯è§†åŒ–")
    
    print("\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    if config.SAVE_PLOTS:
        print(f"   - {config.OUTPUT_DIR}/comprehensive_data_analysis.png                    (æ•°æ®åˆ†æå›¾)")
        print(f"   - {config.OUTPUT_DIR}/comprehensive_performance_comparison.png           (æ ‡å‡†æ€§èƒ½å¯¹æ¯”å›¾)")
        print(f"   - {config.OUTPUT_DIR}/comprehensive_performance_comparison_extended.png  (æ‰©å±•æ€§èƒ½å¯¹æ¯”å›¾)")
        print(f"   - {config.OUTPUT_DIR}/causal_modes_detailed_comparison.png               (CausalEngineæ¨¡å¼ä¸“é¡¹å¯¹æ¯”å›¾)")
    
    print("\nğŸ’¡ æç¤ºï¼šé€šè¿‡ä¿®æ”¹ComprehensiveTutorialConfigç±»æ¥è‡ªå®šä¹‰å®éªŒå‚æ•°ï¼")
    print("ğŸ”¬ ä¸‹ä¸€æ­¥ï¼šå¯ä»¥å°è¯•ä¸åŒçš„æ•°æ®é›†æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°æ¥è¿›ä¸€æ­¥éªŒè¯CausalEngineçš„ä¼˜è¶Šæ€§")


if __name__ == "__main__":
    main()