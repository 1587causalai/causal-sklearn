\documentclass[aspectratio=169,12pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

% ä¸»é¢˜è®¾ç½®
\usetheme{Madrid}
\usecolortheme{default}
\usefonttheme{professionalfonts}

% ä»£ç é«˜äº®è®¾ç½®
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    showstringspaces=false,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10}
}

% æ ‡é¢˜ä¿¡æ¯
\title{CausalEngine: Making Machine Learning Smarter}
\subtitle{ä»ç›¸å…³æ€§åˆ°å› æœæ€§çš„é©å‘½ (From Correlation to Causation)}
\author{é¾šé¹¤é˜³ (Heyang Gong)}
\date{\today}

\begin{document}

% æ ‡é¢˜é¡µ
\begin{frame}
\titlepage
\end{frame}

% ç›®å½•
\begin{frame}{ä»Šå¤©æˆ‘ä»¬è¦è®²ä»€ä¹ˆ? (What are we talking about today?)}
\tableofcontents
\end{frame}

% ç¬¬ä¸€éƒ¨åˆ†ï¼šé—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
\section{ä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆé—®é¢˜? (Problems with Traditional ML)}

\begin{frame}{ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„å±€é™æ€§ (Limitations of Traditional ML)}
\begin{columns}
\column{0.5\textwidth}
\textbf{ä¼ ç»Ÿæœºå™¨å­¦ä¹ åšä»€ä¹ˆ? (What does traditional ML do?)}
\begin{itemize}
    \item å­¦ä¹ æ•°æ®ä¸­çš„ç›¸å…³æ€§ (Learn correlations in data)
    \item å°±åƒ: çœ‹åˆ°ä¹Œäº‘å°±è¯´è¦ä¸‹é›¨ (Like: see clouds, predict rain)
    \item ä½†ä¸çŸ¥é“ä¸ºä»€ä¹ˆä¸‹é›¨ (But don't know WHY it rains)
\end{itemize}

\vspace{1em}
\textbf{é—®é¢˜å‡ºç°äº†: (Problems arise:)}
\begin{itemize}
    \item æ•°æ®æœ‰å™ªéŸ³å°±ä¸å‡†äº† (Fails with noisy data)
    \item æ¯ä¸ªäººçš„å·®å¼‚è¢«å½“ä½œ"å¹²æ‰°" (Individual differences = "noise")
    \item åªèƒ½å‘Šè¯‰ä½ "æ˜¯ä»€ä¹ˆ", ä¸çŸ¥é“"ä¸ºä»€ä¹ˆ" (Tells WHAT, not WHY)
\end{itemize}

\column{0.5\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.8]
% ä¼ ç»ŸMLç¤ºæ„å›¾
\node[draw, fill=blue!20, rounded corners, minimum width=2cm, minimum height=1cm] (x) at (0,0) {Input};
\node[draw, fill=black!20, rounded corners, minimum width=2cm, minimum height=1cm] (box) at (3,0) {Black Box};
\node[draw, fill=red!20, rounded corners, minimum width=2cm, minimum height=1cm] (y) at (6,0) {Output};
\draw[->, thick] (x) -- (box);
\draw[->, thick] (box) -- (y);
\node at (3,-1.5) {\small Don't know what happens inside};
\end{tikzpicture}
\end{center}
\end{columns}

\vspace{1em}
\begin{alertblock}{æ ¸å¿ƒé—®é¢˜ (Core Problem)}
ç°å®ä¸–ç•Œçš„æ•°æ®æ€»æ˜¯æœ‰å™ªéŸ³çš„, ä¼ ç»Ÿæ–¹æ³•åº”ä»˜ä¸äº†! (Real-world data is always noisy, traditional methods can't handle it!)
\end{alertblock}
\end{frame}

\begin{frame}{æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆ? (What kind of solution do we need?)}
\begin{center}
\begin{tikzpicture}[scale=1.2]
% å¯¹æ¯”å›¾
\node at (0,3) {\textbf{\large Traditional Method}};
\node at (6,3) {\textbf{\large Causal Method}};

% ä¼ ç»Ÿæ–¹æ³•
\node[draw, fill=blue!20, rounded corners] (x1) at (-1,1.5) {X};
\node[draw, fill=red!20, rounded corners] (y1) at (1,1.5) {Y};
\draw[->, thick] (x1) -- (y1) node[midway, above] {\small Correlation};

% å› æœæ–¹æ³•
\node[draw, fill=blue!20, rounded corners] (x2) at (5,1.5) {X};
\node[draw, circle, fill=yellow!30] (u) at (6,1.5) {U};
\node[draw, fill=red!20, rounded corners] (y2) at (7,1.5) {Y};
\draw[->, thick] (x2) -- (u);
\draw[->, thick] (u) -- (y2);
\node at (6,0.8) {\small Individual};

% ä¼˜åŠ¿å¯¹æ¯”
\node[align=left] at (0,0) {\small â€¢ Simple \& Direct\\â€¢ Easy to overfit\\â€¢ Noise sensitive};
\node[align=left] at (6,0) {\small â€¢ Understand mechanism\\â€¢ Noise robust\\â€¢ Personalized prediction};
\end{tikzpicture}
\end{center}

\begin{block}{å…³é”®æ´å¯Ÿ (Key Insight)}
æ¯ä¸ªä¸ªä½“éƒ½æœ‰ç‹¬ç‰¹çš„ç‰¹å¾U, è¿™ä¸æ˜¯å™ªéŸ³, è€Œæ˜¯æœ‰ç”¨çš„ä¿¡æ¯! (Each individual has unique feature U - this is not noise, but useful information!)
\end{block}
\end{frame}

% ç¬¬äºŒéƒ¨åˆ†ï¼šå› æœå¼•æ“æ€ä¹ˆå·¥ä½œï¼Ÿ
\section{å› æœå¼•æ“æ˜¯æ€ä¹ˆå·¥ä½œçš„? (How does CausalEngine work?)}

\begin{frame}{å› æœå¼•æ“çš„å››ä¸ªæ­¥éª¤ (CausalEngine's Four Steps)}
\begin{center}
\begin{tikzpicture}[
    scale=1,
    box/.style={draw, rounded corners=5pt, minimum width=1.8cm, minimum height=1cm, font=\small},
    arrow/.style={->, thick, >=Stealth}
]

% ä¸»è¦æµç¨‹
\node[box, fill=blue!20] (X) at (0,0) {Input\\$\mathbf{X}$};
\node[box, fill=green!20] (P) at (2.5,0) {Perception};
\node[box, fill=yellow!20] (Ab) at (5,0) {Abduction};
\node[box, fill=orange!20] (Ac) at (7.5,0) {Action};
\node[box, fill=red!20] (D) at (10,0) {Decision};

% ç®­å¤´å’Œä¸­é—´å˜é‡
\draw[arrow] (X) -- (P);
\draw[arrow] (P) -- (Ab) node[midway, above, font=\small] {$\mathbf{Z}$};
\draw[arrow] (Ab) -- (Ac) node[midway, above, font=\small] {$\mathbf{U}$};
\draw[arrow] (Ac) -- (D) node[midway, above, font=\small] {$\mathbf{S}$};
\draw[arrow] (D) -- ++(1.5,0) node[right, font=\small] {$\mathbf{Y}$};

% ä¸‹æ–¹è¯´æ˜
\node[align=center, font=\footnotesize] at (2.5,-1.5) {Extract features\\Like human vision};
\node[align=center, font=\footnotesize] at (5,-1.5) {Infer causes\\Find individual U};
\node[align=center, font=\footnotesize] at (7.5,-1.5) {Calculate scores\\Prepare decision};
\node[align=center, font=\footnotesize] at (10,-1.5) {Final output\\Give answer};

\end{tikzpicture}
\end{center}

\vspace{1em}
\begin{alertblock}{æ ¸å¿ƒæ€æƒ³ (Core Idea)}
å°±åƒåŒ»ç”Ÿçœ‹ç—…: å…ˆè§‚å¯Ÿç—‡çŠ¶, æ¨æ–­ç—…å› , å†å¯¹ç—‡ä¸‹è¯! (Like a doctor: observe symptoms, infer causes, then treat!)
\end{alertblock}
\end{frame}

% ç¬¬ä¸‰éƒ¨åˆ†ï¼šäº”ç§å·¥ä½œæ¨¡å¼
\section{äº”ç§å·¥ä½œæ¨¡å¼ (Five Working Modes)}

\begin{frame}{äº”ç§æ¨ç†æ¨¡å¼ (Five Inference Modes)}
\begin{center}
\begin{tikzpicture}[scale=0.9]
% ç”»äº”ä¸ªåœ†åœˆä»£è¡¨äº”ç§æ¨¡å¼
\node[circle, draw, fill=gray!20, minimum size=1.5cm] (det) at (0,2) {\small Deterministic};
\node[circle, draw, fill=blue!20, minimum size=1.5cm] (exo) at (-2,0) {\small Exogenous};
\node[circle, draw, fill=green!20, minimum size=1.5cm] (endo) at (2,0) {\small Endogenous};
\node[circle, draw, fill=red!30, minimum size=1.8cm] (std) at (0,-2) {\textbf{Standard}};
\node[circle, draw, fill=yellow!20, minimum size=1.5cm] (samp) at (0,0) {\small Sampling};

% è¿çº¿
\draw[dashed] (exo) -- (std);
\draw[dashed] (endo) -- (std);

% è¯´æ˜
\node at (0,3.5) {\textbf{Five Inference Modes}};
\node[align=center] at (-4,0) {\small Environmental\\noise};
\node[align=center] at (4,0) {\small Cognitive\\uncertainty};
\node[align=center] at (0,-3.5) {\textbf{Standard Mode}\\Combines both};
\end{tikzpicture}
\end{center}

\begin{alertblock}{æ¨èä½¿ç”¨ (Recommended)}
\textbf{æ ‡å‡†æ¨¡å¼ (Standard mode)} åœ¨å¤§å¤šæ•°å®é™…åº”ç”¨ä¸­æ•ˆæœæœ€å¥½! (works best in most real applications!)
\end{alertblock}
\end{frame}

% ç¬¬å››éƒ¨åˆ†ï¼šæ€§èƒ½æœ‰å¤šå¥½ï¼Ÿ
\section{å› æœå¼•æ“çš„æ€§èƒ½æœ‰å¤šå¥½? (How good is the performance?)}

\begin{frame}{æŠ—å™ªéŸ³èƒ½åŠ›æµ‹è¯•: å›å½’ä»»åŠ¡ (Noise Robustness Test: Regression)}
\begin{columns}
\column{0.5\textwidth}
\begin{center}
\textbf{éšç€å™ªéŸ³å¢åŠ , æ€§èƒ½å¦‚ä½•å˜åŒ–? (How does performance change with noise?)}
\begin{tikzpicture}[scale=0.7]
\draw[->] (0,0) -- (5,0) node[right] {Noise Level};
\draw[->] (0,0) -- (0,4) node[above] {Error};

% æ€§èƒ½æ›²çº¿ï¼ˆç®€åŒ–ï¼‰
\draw[red, very thick] (0,0.5) -- (1,1.5) -- (2,2.5) -- (3,3.5) -- (4,3.8);
\draw[blue, very thick] (0,0.5) -- (1,1.2) -- (2,2.2) -- (3,3.2) -- (4,3.5);
\draw[green, ultra thick] (0,0.5) -- (1,0.7) -- (2,0.9) -- (3,1.2) -- (4,1.5);

% å›¾ä¾‹
\node[red] at (5.2,3.6) {\tiny Traditional};
\node[blue] at (5.2,3.3) {\tiny PyTorch};
\node[green] at (5.2,1.3) {\tiny CausalEngine};

% Xè½´æ ‡ç­¾
\node at (0,-0.3) {\tiny 0\%};
\node at (2,-0.3) {\tiny 30\%};
\node at (4,-0.3) {\tiny 50\%};
\end{tikzpicture}
\end{center}

\column{0.5\textwidth}
\textbf{30\%æ ‡ç­¾å™ªéŸ³ä¸‹çš„è¡¨ç°: (Performance at 30\% label noise:)}
\begin{itemize}
    \item Traditional MLP: Error 47.60
    \item PyTorch: Error 45.32
    \item \textcolor{green}{\textbf{CausalEngine: Error 11.41}}
\end{itemize}

\vspace{1em}
\begin{alertblock}{æƒŠäººæå‡ (Amazing improvement)}
\textbf{æ€§èƒ½æå‡76\%! (76\% improvement!)}
\end{alertblock}
\end{columns}

\vspace{1em}
\begin{block}{å…³é”®å‘ç° (Key Finding)}
å™ªéŸ³è¶Šå¤š, å› æœå¼•æ“çš„ä¼˜åŠ¿è¶Šæ˜æ˜¾! (More noise = more advantage for CausalEngine!)
\end{block}
\end{frame}

% ç¬¬äº”éƒ¨åˆ†ï¼šæ€ä¹ˆä½¿ç”¨ï¼Ÿ
\section{æ€ä¹ˆä½¿ç”¨å› æœå¼•æ“? (How to use CausalEngine?)}

\begin{frame}[fragile]{å®‰è£…å’ŒåŸºæœ¬ä½¿ç”¨ (Installation and Basic Usage)}
\begin{block}{å®‰è£…å¾ˆç®€å• (Installation is simple)}
\begin{lstlisting}
pip install causal-sklearn
\end{lstlisting}
\end{block}

\begin{block}{åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ (Basic Usage Example)}
\begin{lstlisting}
from causal_sklearn import MLPCausalRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# Generate data
X, y = make_regression(n_samples=1000, n_features=10, noise=20)
X_train, X_test, y_train, y_test = train_test_split(X, y)

# Create and train model
model = MLPCausalRegressor(
    hidden_layer_sizes=(100, 50),
    inference_mode='standard',  # Recommended mode
    max_iter=200
)
model.fit(X_train, y_train)

# Predict and evaluate
score = model.score(X_test, y_test)
print(f"Test score: {score:.4f}")
\end{lstlisting}
\end{block}
\end{frame}

% ç¬¬å…­éƒ¨åˆ†ï¼šåº”ç”¨åœºæ™¯
\section{é€‚ç”¨åœºæ™¯ (Use Cases)}

\begin{frame}{ä»€ä¹ˆæ—¶å€™ç”¨å› æœå¼•æ“? (When to use CausalEngine?)}
\begin{columns}
\column{0.5\textwidth}
\textbf{ç‰¹åˆ«é€‚åˆçš„åœºæ™¯: (Particularly suitable:)}
\begin{itemize}
    \item $\checkmark$ æ•°æ®æœ‰å¾ˆå¤šå™ªéŸ³çš„æ—¶å€™ (Noisy data)
    \item $\checkmark$ éœ€è¦ç†è§£ä¸ªä½“å·®å¼‚ (Individual differences matter)
    \item $\checkmark$ åŒ»ç–—è¯Šæ–­ (Medical diagnosis)
    \item $\checkmark$ é‡‘èé£é™©è¯„ä¼° (Financial risk)
    \item $\checkmark$ æ¨èç³»ç»Ÿ (Recommendation systems)
    \item $\checkmark$ å¼‚å¸¸æ£€æµ‹ (Anomaly detection)
\end{itemize}

\column{0.5\textwidth}
\textbf{ä¼˜åŠ¿ä¸æ˜æ˜¾çš„åœºæ™¯: (Limited advantage:)}
\begin{itemize}
    \item $\times$ æ•°æ®éå¸¸å¹²å‡€ (Very clean data)
    \item $\times$ çº¯å›¾åƒåˆ†ç±» (Pure image classification)
    \item $\times$ ä¸éœ€è¦è§£é‡Šæ€§çš„åœºæ™¯ (No interpretability needed)
    \item $\times$ è®¡ç®—èµ„æºæå…¶æœ‰é™ (Very limited computation)
\end{itemize}
\end{columns}

\vspace{1em}
\begin{block}{ç»éªŒæ³•åˆ™ (Rule of thumb)}
å½“æ•°æ®è´¨é‡ä¸ç¡®å®šæˆ–éœ€è¦é²æ£’æ€§æ—¶, å› æœå¼•æ“æ˜¯ç†æƒ³é€‰æ‹© (When data quality is uncertain or robustness is needed, CausalEngine is ideal)
\end{block}
\end{frame}

% ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ€»ç»“
\section{æ€»ç»“ä¸å±•æœ› (Summary and Outlook)}

\begin{frame}{æ ¸å¿ƒè´¡çŒ® (Core Contributions)}
\begin{enumerate}
    \item \textbf{æ–°çš„æœºå™¨å­¦ä¹ èŒƒå¼ (New ML Paradigm)}
    \begin{itemize}
        \item ä»å­¦ä¹ ç›¸å…³æ€§åˆ°å­¦ä¹ å› æœå…³ç³» (From correlation to causation)
        \item æŠŠä¸ªä½“å·®å¼‚å½“ä½œç‰¹å¾, è€Œä¸æ˜¯å™ªéŸ³ (Individual differences as features, not noise)
    \end{itemize}
    
    \item \textbf{å®ç”¨çš„å®ç° (Practical Implementation)}
    \begin{itemize}
        \item å®Œå…¨å…¼å®¹scikit-learn API (Full scikit-learn compatibility)
        \item é«˜æ•ˆçš„åˆ†æè®¡ç®— (Efficient analytical computation)
        \item å®¹æ˜“é›†æˆåˆ°ç°æœ‰å·¥ä½œæµç¨‹ (Easy integration)
    \end{itemize}
    
    \item \textbf{å‡ºè‰²çš„é²æ£’æ€§ (Exceptional Robustness)}
    \begin{itemize}
        \item åœ¨å™ªéŸ³ç¯å¢ƒä¸­æ€§èƒ½ä¼˜å¼‚ (Superior performance in noisy environments)
        \item é€‚åˆç°å®ä¸–ç•Œçš„æ··ä¹±æ•°æ® (Suitable for real-world messy data)
    \end{itemize}
\end{enumerate}

\vspace{1em}
\begin{block}{ä¸€å¥è¯æ€»ç»“ (One-sentence Summary)}
å› æœå¼•æ“é€šè¿‡ç†è§£"ä¸ºä»€ä¹ˆ"è€Œä¸ä»…ä»…æ˜¯"æ˜¯ä»€ä¹ˆ", ä¸ºæœºå™¨å­¦ä¹ å¸¦æ¥æ–°çš„å¯èƒ½æ€§ (CausalEngine brings new possibilities to ML by understanding WHY, not just WHAT)
\end{block}
\end{frame}

\begin{frame}
\begin{center}
{\Huge \textbf{è°¢è°¢å¤§å®¶! (Thank You!)}}

\vspace{2em}

{\Large æœ‰é—®é¢˜å¯ä»¥è®¨è®º (Questions \& Discussion)}

\vspace{2em}

{\large è®©æœºå™¨å­¦ä¹ å˜å¾—æ›´æ™ºèƒ½ (Making ML Smarter) ğŸš€}
\end{center}
\end{frame}

\end{document}